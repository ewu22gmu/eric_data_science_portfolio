{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BGXt8Oqy-7mi"},"outputs":[],"source":["### ANALYZING SENTENCE STRUCTURE\n","\n","## The purpose of a grammar is to give an explicit description of a language. But the way in which we think of a grammar is closely intertwined with what we consider to be a language.\n","#Is it a large but finite set of observed utterances and written texts? Is it something more abstract like the implicit knowledge that competent speakers have about grammatical sentences?\n","#Or is it some combination of the two?\n","\n","## A well-known example of ambiguity is shown here, from the Groucho Marx movie, Animal Crackers (1930):\n","\n","\n","# While hunting in Africa, I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\n","\n","\n","## Let's take a closer look at the ambiguity in the phrase: I shot an elephant in my pajamas. First we need to define a simple grammar:\n","\n","import nltk\n","\n","groucho_grammar = nltk.CFG.fromstring(\"\"\"\n","S -> NP VP\n","PP -> P NP\n","NP -> Det N | Det N PP | 'I'\n","VP -> V NP | VP PP\n","Det -> 'an' | 'my'\n","N -> 'elephant' | 'pajamas'\n","V -> 'shot'\n","P -> 'in'\n","\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IkBVBsgY-7mk","executionInfo":{"status":"ok","timestamp":1743122328911,"user_tz":240,"elapsed":4,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"13e3c2d2-8f21-4fa9-c687-0191b98283f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (NP I)\n","  (VP\n","    (VP (V shot) (NP (Det an) (N elephant)))\n","    (PP (P in) (NP (Det my) (N pajamas)))))\n","(S\n","  (NP I)\n","  (VP\n","    (V shot)\n","    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"]}],"source":["# This grammar permits the sentence to be analyzed in two ways, depending on whether the prepositional phrase in my pajamas describes the elephant or the shooting event.\n","\n","sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n","parser = nltk.ChartParser(groucho_grammar)\n","for tree in parser.parse(sent):\n","    print(tree)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ntq1g0Tl-7ml"},"outputs":[],"source":["## Notice that there's no ambiguity concerning the meaning of any of the words; e.g. the word shot doesn't refer to the act of using a gun in the first sentence,\n","#and using a camera in the second sentence.\n","\n","## Coordinate Structure:\n","\n","## If v1 and v2 are both phrases of grammatical category X, then v1 and v2 is also a phrase of category X.\n","## Here are a couple of examples. In the first, two NPs (noun phrases) have been conjoined to make an NP, while in the second, two APs (adjective phrases) have been conjoined to make an AP.\n","\n","\n","# a. The book's ending was (NP the worst part and the best part) for me.\n","# b. On land they are (AP slow and clumsy looking).\n","\n","\n","## What we can't do is conjoin an NP and an AP, which is why the worst part and clumsy looking is ungrammatical.\n","#Before we can formalize these ideas, we need to understand the concept of constituent structure.\n","\n","## Constituent structure is based on the observation that words combine with other words to form units.\n","#The evidence that a sequence of words forms such a unit is given by substitutability — that is, a sequence of words in a well-formed sentence can be replaced by a shorter sequence\n","# without rendering the sentence ill-formed. To clarify this idea, consider the following sentence:\n","\n","\n","# The little bear saw the fine fat trout in the brook.\n","\n","\n","## The fact that we can substitute He for The little bear indicates that the latter sequence is a unit. By contrast, we cannot replace little bear saw in the same way.\n","\n","\n","# He saw the fine fat trout in the brook.\n","# The he the fine fat trout in the brook.\n","\n","## We systematically substitute longer sequences by shorter ones in a way which preserves grammaticality.\n","#Each sequence that forms a unit can in fact be replaced by a single word, and we end up with just two elements.\n","\n","## We add grammatical category labels to the words. The labels NP, VP, and PP stand for noun phrase, verb phrase and prepositional phrase respectively.\n","## Each node in the tree (including the words) is called a constituent. The immediate constituents of S are NP and VP.\n","\n","## A SIMPLE GRAMMAR\n","## Let's start off by looking at a simple context-free grammar. By convention, the left-hand-side of the first production is the start-symbol of the grammar,\n","#typically S, and all well-formed trees must have this symbol as their root label. In NLTK, context-free grammars are defined in the nltk.grammar module.\n","#We define a grammar and show how to parse a simple sentence admitted by the grammar.\n","\n","grammar1 = nltk.CFG.fromstring(\"\"\"\n","  S -> NP VP\n","  VP -> V NP | V NP PP\n","  PP -> P NP\n","  V -> \"saw\" | \"ate\" | \"walked\"\n","  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n","  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n","  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n","  P -> \"in\" | \"on\" | \"by\" | \"with\"\n","  \"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"aslPnsxV-7ml","executionInfo":{"status":"ok","timestamp":1743122328931,"user_tz":240,"elapsed":19,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"e63723bc-f85a-43e1-9afe-9e90b4a8d463"},"outputs":[{"output_type":"stream","name":"stdout","text":["(S (NP Mary) (VP (V saw) (NP Bob)))\n"]}],"source":["sent = \"Mary saw Bob\".split()\n","rd_parser = nltk.RecursiveDescentParser(grammar1)\n","for tree in rd_parser.parse(sent):\n","    print(tree)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"0FnWzHB_-7mm"},"outputs":[],"source":["# A production like VP -> V NP | V NP PP has a disjunction on the righthand side, shown by the | and is an abbreviation for the two productions VP -> V NP and VP -> V NP PP.\n","# If our grammar licenses two trees for this sentence, the sentence is said to be structurally ambiguous.\n","\n","## Recursion in Syntactic Structure\n","\n","# A grammar is said to be recursive if a category occurring on the left hand side of a production also appears on the righthand side of a production.\n","# The production Nom -> Adj Nom (where Nom is the category of nominals) involves direct recursion on the category Nom,\n","#whereas indirect recursion on S arises from the combination of two productions, namely S -> NP VP and VP -> V S.\n","\n","grammar2 = nltk.CFG.fromstring(\"\"\"\n","  S  -> NP VP\n","  NP -> Det Nom | PropN\n","  Nom -> Adj Nom | N\n","  VP -> V Adj | V NP | V S | V NP PP\n","  PP -> P NP\n","  PropN -> 'Buster' | 'Chatterer' | 'Joe'\n","  Det -> 'the' | 'a'\n","  N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n","  Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n","  V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n","  P -> 'on'\n","  \"\"\")\n","\n","# We've only illustrated two levels of recursion here, but there's no upper limit on the depth. You can experiment with parsing sentences that involve more deeply nested structures. Beware that the RecursiveDescentParser is unable to handle left-recursive productions of the form X -> X Y;"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_f-YjCi-7mm","executionInfo":{"status":"ok","timestamp":1743122329001,"user_tz":240,"elapsed":2,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"da6104b7-d0ed-4bf7-c456-0bf39181586c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"]}],"source":["## PARSING WITH CONTEXT FREE GRAMMAR\n","\n","## A parser processes input sentences according to the productions of a grammar, and builds one or more constituent structures that conform to the grammar.\n","#A grammar is a declarative specification of well-formedness — it is actually just a string, not a program. A parser is a procedural interpretation of the grammar.\n","#It searches through the space of trees licensed by a grammar to find one that has the required sentence along its fringe.\n","\n","## A parser permits a grammar to be evaluated against a collection of test sentences, helping linguists to discover mistakes in their grammatical analysis.\n","#A parser can serve as a model of psycholinguistic processing, helping to explain the difficulties that humans have with processing certain syntactic constructions.\n","#Many natural language applications involve parsing at some point; for example, we would expect the natural language questions submitted to a question-answering system to undergo parsing as an initial step.\n","\n","## RECURSIVE DESCENT PARSER\n","# The simplest kind of parser interprets a grammar as a specification of how to break a high-level goal into several lower-level subgoals.\n","#The top-level goal is to find an S. The S → NP VP production permits the parser to replace this goal with two subgoals: find an NP, then find a VP.\n","#Each of these subgoals can be replaced in turn by sub-sub-goals, using productions that have NP and VP on their left-hand side.\n","#Eventually, this expansion process leads to subgoals such as: find the word telescope.\n","#Such subgoals can be directly compared against the input sequence, and succeed if the next word is matched. If there is no match the parser must back up and try a different alternative.\n","\n","rd_parser = nltk.RecursiveDescentParser(grammar1)\n","sent = 'Mary saw a dog'.split()\n","for tree in rd_parser.parse(sent):\n","    print(tree)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rkgxghxv-7mm","executionInfo":{"status":"ok","timestamp":1743122329120,"user_tz":240,"elapsed":74,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"beb26f08-e29d-4b3d-f225-b1bce13f4f9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"]}],"source":["## Recursive descent parsing has three key shortcomings. First, left-recursive productions like NP -> NP PP send it into an infinite loop.\n","#Second, the parser wastes a lot of time considering words and structures that do not correspond to the input sentence.\n","#Third, the backtracking process may discard parsed constituents that will need to be rebuilt again later.\n","#For example, backtracking over VP -> V NP will discard the subtree created for the NP. If the parser then proceeds with VP -> V NP PP, then the NP subtree must be created all over again.\n","\n","## Recursive descent parsing is a kind of top-down parsing. Top-down parsers use a grammar to predict what the input will be, before inspecting the input!\n","#However, since the input is available to the parser all along, it would be more sensible to consider the input sentence from the very beginning. This approach is called bottom-up parsing.\n","\n","## SHIFT REDUCE PARSING\n","# In common with all bottom-up parsers, a shift-reduce parser tries to find sequences of words and phrases that correspond to the right hand side of a grammar production, and replace them\n","#with the left-hand side, until the whole sentence is reduced to an S.\n","\n","sr_parser = nltk.ShiftReduceParser(grammar1)\n","sent = 'Mary saw a dog'.split()\n","for tree in sr_parser.parse(sent):\n","    print(tree)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xs8kDsCR-7mm","executionInfo":{"status":"ok","timestamp":1743122329124,"user_tz":240,"elapsed":3,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"c39d1e2a-e658-4d28-8ecf-f396cfe9b127"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[V -> 'shot']"]},"metadata":{},"execution_count":8}],"source":["## WELL FORMED SUBSTRING TABLES (WFST)\n","\n","#The simple parsers discussed above suffer from limitations in both completeness and efficiency.\n","#In order to remedy these, we will apply the algorithm design technique of dynamic programming to the parsing problem.\n","\n","#This technique can be applied to syntactic parsing, allowing us to store partial solutions to the parsing task and then look them up as necessary in order to\n","#efficiently arrive at a complete solution. This approach to parsing is known as chart parsing.\n","\n","text = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n","groucho_grammar.productions(rhs=text[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mBdYiA9T-7mm"},"outputs":[],"source":["# For our WFST, we create an (n-1) × (n-1) matrix as a list of lists in Python, and initialize it with the lexical categories of each token, in the init_wfst() function.\n","#We also define a utility function display() to pretty-print the WFST.\n","\n","def init_wfst(tokens, grammar):\n","    numtokens = len(tokens)\n","    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n","    for i in range(numtokens):\n","        productions = grammar.productions(rhs=tokens[i])\n","        wfst[i][i+1] = productions[0].lhs()\n","    return wfst\n","\n","def complete_wfst(wfst, tokens, grammar, trace=False):\n","    index = dict((p.rhs(), p.lhs()) for p in grammar.productions())\n","    numtokens = len(tokens)\n","    for span in range(2, numtokens+1):\n","        for start in range(numtokens+1-span):\n","            end = start + span\n","            for mid in range(start+1, end):\n","                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n","                if nt1 and nt2 and (nt1,nt2) in index:\n","                    wfst[start][end] = index[(nt1,nt2)]\n","                    if trace:\n","                        print(\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % \\\n","                        (start, nt1, mid, nt2, end, start, index[(nt1,nt2)], end))\n","    return wfst\n","\n","def display(wfst, tokens):\n","    print('\\nWFST ' + ' '.join((\"%-4d\" % i) for i in range(1, len(wfst))))\n","    for i in range(len(wfst)-1):\n","        print(\"%d   \" % i, end=\" \")\n","        for j in range(1, len(wfst)):\n","            print(\"%-4s\" % (wfst[i][j] or '.'), end=\" \")\n","        print()"]},{"cell_type":"code","source":["groucho_grammar = nltk.CFG.fromstring(\"\"\"\n","S -> NP VP\n","PP -> P NP\n","NP -> Det N | Det N PP | 'I'\n","VP -> V NP | VP PP\n","Det -> 'an' | 'my'\n","N -> 'elephant' | 'pajamas'\n","V -> 'shot'\n","P -> 'in'\n","\"\"\")\n","\n","tokens = \"I shot an elephant in my pajamas\".split()\n","wfst0 = init_wfst(tokens, groucho_grammar)\n","display(wfst0, tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKIhBl01NMM0","executionInfo":{"status":"ok","timestamp":1743123216039,"user_tz":240,"elapsed":46,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"ebd3690e-9d89-418d-cd12-fc3251b0573c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","WFST 1    2    3    4    5    6    7   \n","0    NP   .    .    .    .    .    .    \n","1    .    V    .    .    .    .    .    \n","2    .    .    Det  .    .    .    .    \n","3    .    .    .    N    .    .    .    \n","4    .    .    .    .    P    .    .    \n","5    .    .    .    .    .    Det  .    \n","6    .    .    .    .    .    .    N    \n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvL270Cz-7mm","executionInfo":{"status":"ok","timestamp":1743123216688,"user_tz":240,"elapsed":2,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"e683cea5-2e4c-4c2f-9e61-e9d1df378ae0"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2] Det [3]   N [4] ==> [2]  NP [4]\n","[5] Det [6]   N [7] ==> [5]  NP [7]\n","[1]   V [2]  NP [4] ==> [1]  VP [4]\n","[4]   P [5]  NP [7] ==> [4]  PP [7]\n","[0]  NP [1]  VP [4] ==> [0]   S [4]\n","[1]  VP [4]  PP [7] ==> [1]  VP [7]\n","[0]  NP [1]  VP [7] ==> [0]   S [7]\n","\n","WFST 1    2    3    4    5    6    7   \n","0    NP   .    .    S    .    .    S    \n","1    .    V    .    VP   .    .    VP   \n","2    .    .    Det  NP   .    .    .    \n","3    .    .    .    N    .    .    .    \n","4    .    .    .    .    P    .    PP   \n","5    .    .    .    .    .    Det  NP   \n","6    .    .    .    .    .    .    N    \n"]}],"source":["wfst1 = complete_wfst(wfst0, tokens, groucho_grammar,True)\n","display(wfst1, tokens)"]},{"cell_type":"code","source":["wfst2 = complete_wfst(wfst1, tokens, groucho_grammar,True)\n","display(wfst2, tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYtss1mTMQYR","executionInfo":{"status":"ok","timestamp":1743123219192,"user_tz":240,"elapsed":4,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"2ae83c13-0184-4d43-dd98-94365e47e9a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2] Det [3]   N [4] ==> [2]  NP [4]\n","[5] Det [6]   N [7] ==> [5]  NP [7]\n","[1]   V [2]  NP [4] ==> [1]  VP [4]\n","[4]   P [5]  NP [7] ==> [4]  PP [7]\n","[0]  NP [1]  VP [4] ==> [0]   S [4]\n","[1]  VP [4]  PP [7] ==> [1]  VP [7]\n","[0]  NP [1]  VP [7] ==> [0]   S [7]\n","\n","WFST 1    2    3    4    5    6    7   \n","0    NP   .    .    S    .    .    S    \n","1    .    V    .    VP   .    .    VP   \n","2    .    .    Det  NP   .    .    .    \n","3    .    .    .    N    .    .    .    \n","4    .    .    .    .    P    .    PP   \n","5    .    .    .    .    .    Det  NP   \n","6    .    .    .    .    .    .    N    \n"]}]},{"cell_type":"code","source":["wfst3 = complete_wfst(wfst2, tokens, groucho_grammar)\n","display(wfst3, tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7EGknM3UMaPc","executionInfo":{"status":"ok","timestamp":1743123030292,"user_tz":240,"elapsed":5,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"861206b9-17d2-4075-86c8-c85f996f6615"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","WFST 1    2    3    4    5    6    7   \n","0    NP   .    .    S    .    .    S    \n","1    .    V    .    VP   .    .    VP   \n","2    .    .    Det  NP   .    .    .    \n","3    .    .    .    N    .    .    .    \n","4    .    .    .    .    P    .    PP   \n","5    .    .    .    .    .    Det  NP   \n","6    .    .    .    .    .    .    N    \n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIzws6uu-7mn"},"outputs":[],"source":["## WFST's have several shortcomings. First, as you can see, the WFST is not itself a parse tree, so the technique is strictly speaking recognizing that a sentence is admitted by a grammar,\n","#rather than parsing it.\n","\n","## Second, it requires every non-lexical grammar production to be binary. Although it is possible to convert an arbitrary CFG into this form,\n","#we would prefer to use an approach without such a requirement. Third, as a bottom-up approach it is potentially wasteful, being able to propose constituents in locations\n","#that would not be licensed by the grammar.\n","\n","## Finally, the WFST did not represent the structural ambiguity in the sentence (i.e. the two verb phrase readings)."]},{"cell_type":"code","source":["import nltk\n","nltk.download('treebank',quiet=True)\n","\n","print(nltk.corpus.treebank.parsed_sents('wsj_0001.mrg')[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_RQ0OGgvhLQ","executionInfo":{"status":"ok","timestamp":1743702179288,"user_tz":240,"elapsed":575,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"7caa818c-949d-4d86-8325-2cb19d57371a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (NP-SBJ (NNP Mr.) (NNP Vinken))\n","  (VP\n","    (VBZ is)\n","    (NP-PRD\n","      (NP (NN chairman))\n","      (PP\n","        (IN of)\n","        (NP\n","          (NP (NNP Elsevier) (NNP N.V.))\n","          (, ,)\n","          (NP (DT the) (NNP Dutch) (VBG publishing) (NN group))))))\n","  (. .))\n"]}]},{"cell_type":"code","source":["import matplotlib\n","import tkinter\n","from nltk.draw.tree import draw_trees\n","from nltk.tree import Tree\n","\n","matplotlib.use('Agg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQyoozibwJEO","executionInfo":{"status":"ok","timestamp":1743702513617,"user_tz":240,"elapsed":7825,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"8d14fb3b-55d6-4a36-9583-084b9cded330"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","python3-tk is already the newest version (3.10.8-1~22.04).\n","0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"]}]},{"cell_type":"code","source":["draw_trees(nltk.corpus.treebank.parsed_sents('wsj_0001.mrg')[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"9nagzGC6vxV0","executionInfo":{"status":"error","timestamp":1743702586472,"user_tz":240,"elapsed":19,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"b78165bc-714e-4f0d-9e61-c6635d9b32d0"},"execution_count":18,"outputs":[{"output_type":"error","ename":"TclError","evalue":"no display name and no $DISPLAY environment variable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-bf0716151e05>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreebank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wsj_0001.mrg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[0;34m(*trees)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \"\"\"\n\u001b[0;32m-> 1008\u001b[0;31m     \u001b[0mTreeView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *trees)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NLTK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<Control-x>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"]}]},{"cell_type":"code","source":["tree = nltk.corpus.treebank.parsed_sents('wsj_0001.mrg')[0]  # Get the first parsed sentence\n","\n","# Print the tree using pretty_print\n","tree.pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ac0FA5d4v2uE","executionInfo":{"status":"ok","timestamp":1743702810221,"user_tz":240,"elapsed":8,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"1c5e340c-2729-423d-9389-b8b4fe7b57bc"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                     S                                                                         \n","                         ____________________________|_______________________________________________________________________   \n","                        |                                               VP                                                   | \n","                        |                        _______________________|___                                                 |  \n","                      NP-SBJ                    |                           VP                                               | \n","         _______________|___________________    |     ______________________|______________________________________          |  \n","        |          |              ADJP      |   |    |        |                PP-CLR                              |         | \n","        |          |           ____|____    |   |    |        |          ________|_________                        |         |  \n","        NP         |          NP        |   |   |    |        NP        |                  NP                    NP-TMP      | \n","   _____|____      |     _____|____     |   |   |    |     ___|____     |    ______________|__________        _____|_____    |  \n"," NNP        NNP    ,    CD        NNS   JJ  ,   MD   VB   DT       NN   IN  DT             JJ         NN    NNP          CD  . \n","  |          |     |    |          |    |   |   |    |    |        |    |   |              |          |      |           |   |  \n","Pierre     Vinken  ,    61       years old  ,  will join the     board  as  a         nonexecutive director Nov.         29  . \n","\n"]}]},{"cell_type":"code","source":["print(tree[0,0,1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxlB5eIZyMVY","executionInfo":{"status":"ok","timestamp":1743702863370,"user_tz":240,"elapsed":11,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"2f2e5458-7d39-4118-b99b-df4654e20d0b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["(NNP Vinken)\n"]}]},{"cell_type":"code","source":["print(tree.height())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYrOT-02yX1E","executionInfo":{"status":"ok","timestamp":1743702887109,"user_tz":240,"elapsed":13,"user":{"displayName":"Eric Wu","userId":"12657333118463688685"}},"outputId":"0da2c291-c433-43a5-f548-39d8aab648df"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"02_40aCDym_S"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}